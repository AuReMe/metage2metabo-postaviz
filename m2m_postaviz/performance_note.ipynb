{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/home/lbrindel/output/western_diet_samples/all_samples/\"\n",
    "metadata = \"~/Downloads/western_diet_exp/metadata_drama.tsv\"\n",
    "abundance_path = \"~/Downloads/western_diet_exp/specI.mat\"\n",
    "taxonomic_path = \"~/Downloads/western_diet_exp/taxonomies.tsv\"\n",
    "save_path = \"/home/lbrindel/output/save_output_m2m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padmet.utils.sbmlPlugin import convert_from_coded_id as cfci\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def get_scopes(file_name, path) -> pd.DataFrame:\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if file_name in files:\n",
    "            scope_matrix = open_tsv(os.path.join(root, file_name), convert_cpd_id=True, rename_columns=True)\n",
    "            return scope_matrix\n",
    "\n",
    "\n",
    "def retrieve_all_sample_data_old_way(path):\n",
    "    \"\"\"Retrieve iscope, cscope, added_value and contribution_of_microbes files in the path given using os.listdir().\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory path\n",
    "\n",
    "    Returns:\n",
    "        dict: Return a nested dict object where each key is a dictionnary of a sample. The key of those second layer dict [iscope, cscope, advalue, contribution] give acces to these files.\n",
    "    \"\"\"\n",
    "    all_sample_data = {}\n",
    "    for sample in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, sample)):\n",
    "            all_sample_data[sample] = {}\n",
    "            all_sample_data[sample][\"cscope\"] = get_scopes(\"rev_cscope.tsv\", os.path.join(path, sample))\n",
    "            \n",
    "    return all_sample_data\n",
    "\n",
    "\n",
    "def retrieve_all_sample_data(sample, path):\n",
    "    \"\"\"Retrieve iscope, cscope, added_value and contribution_of_microbes files in the path given using os.listdir().\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory path\n",
    "\n",
    "    Returns:\n",
    "        dict: Return a nested dict object where each key is a dictionnary of a sample. The key of those second layer dict [iscope, cscope, advalue, contribution] give acces to these files.\n",
    "    \"\"\"\n",
    "    sample_directory_path = os.path.join(path, sample)\n",
    "    if os.path.isdir(sample_directory_path):\n",
    "\n",
    "        cscope_dataframe = get_scopes(\"rev_cscope.tsv\", sample_directory_path)\n",
    "        if cscope_dataframe is None:\n",
    "            return None, sample\n",
    "\n",
    "    return cscope_dataframe, sample\n",
    "\n",
    "\n",
    "def melt_df_multi(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe.reset_index(inplace=True)\n",
    "    return dataframe.melt(\"smplID\",var_name=\"Compound\",value_name=\"Value\")\n",
    "\n",
    "\n",
    "def add_factor_column(metadata, serie_id, factor_id):\n",
    "    if not is_indexed_by_id(metadata):\n",
    "        metadata = metadata.set_index(\"smplID\", drop=True)\n",
    "    new_col = []\n",
    "    for value in serie_id:\n",
    "        new_col.append(str(metadata.at[value, factor_id]))\n",
    "    return new_col\n",
    "\n",
    "\n",
    "def is_indexed_by_id(df: pd.DataFrame):\n",
    "    if df.index.name == \"smplID\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def multiprocess_retrieve_data(path):\n",
    "    \"\"\"Open all directories given in -d path input. Get all cscopes tsv and load them in emomry as pandas\n",
    "    dataframe. Also return a dataframe with the total production by each sample. \n",
    "\n",
    "    Args:\n",
    "        path (str): Path of directory\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (Dict , Dataframe)\n",
    "    \"\"\"\n",
    "    retrieve_data = partial(retrieve_all_sample_data, path=path)\n",
    "\n",
    "    nb_cpu = cpu_count() - 1\n",
    "    if not type(nb_cpu) == int or nb_cpu < 1:\n",
    "        nb_cpu = 1\n",
    "    pool = Pool(nb_cpu)\n",
    "\n",
    "    results_list = pool.map(retrieve_data,[sample for sample in os.listdir(path)])\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    all_data = {}\n",
    "    for df, smpl in results_list:\n",
    "        if not df is None: \n",
    "            all_data[smpl] = {}\n",
    "            all_data[smpl][\"cscope\"] = df\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def sbml_to_classic(compounds_list):\n",
    "    uncoded = []\n",
    "    for coded in compounds_list:\n",
    "        id, id_type, compart = cfci(coded)\n",
    "        new_value = str(id)+\"[\"+str(compart)+\"]\"\n",
    "        uncoded.append(new_value)\n",
    "    return uncoded\n",
    "\n",
    "def open_tsv(file_name: str, convert_cpd_id: bool = False, rename_columns: bool = False, first_col: str = \"smplID\"):\n",
    "    \"\"\"Open tsv file as a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): Path of the file\n",
    "        rename_columns (bool, optional): Rename the first column and decode the metabolites names in sbml format into readable format. Defaults to False.\n",
    "        first_col (str, optional): Label of the first col if rename_columns is True. Defaults to \"smplID\".\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Pandas dataframe\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_name, sep=\"\\t\")\n",
    "    if rename_columns:\n",
    "        data.columns.values[0] = first_col\n",
    "    if convert_cpd_id:\n",
    "        data.set_index(first_col,inplace=True,drop=True)\n",
    "        data.columns = sbml_to_classic(data.columns.values)\n",
    "    return data\n",
    "\n",
    "def build_df(dir_path, metadata, abundance_path: str = None, taxonomic_path: str = None):\n",
    "    \"\"\"\n",
    "    Extract community scopes present in directory from CLI then build a single dataframe from the metabolites produced by each comm_scopes.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): Directory path containing comm scopes\n",
    "        metadata (tsv file): tsv file containing the metadata of the scopes. The number of row must be equal to the number of comm_scopes given in dir_path.\n",
    "\n",
    "    Returns:\n",
    "        global_data: dict\n",
    "        sample_data: dict\n",
    "        abundance_data: pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    all_data = {}\n",
    "\n",
    "    all_data[\"metadata\"] = open_tsv(metadata)\n",
    "    # print(all_data[\"metadata\"].dtypes)\n",
    "\n",
    "    # ## AUTO-CONVERT when opening seems fine.\n",
    "    # all_data[\"metadata\"] = all_data[\"metadata\"].convert_dtypes()\n",
    "    # print(all_data[\"metadata\"].dtypes)\n",
    "    # quit()\n",
    "    all_data[\"sample_data\"], all_data[\"producers_long_format\"] = multiprocess_retrieve_data(dir_path, all_data[\"metadata\"])\n",
    "    quit()\n",
    "    main_df = build_main_dataframe(all_data[\"sample_data\"])\n",
    "\n",
    "    all_data[\"main_dataframe\"] = main_df\n",
    "\n",
    "    if abundance_path is not None:\n",
    "        try:\n",
    "            raw_abundance_file = open_tsv(abundance_path)\n",
    "            normalised_abundance_dataframe = relative_abundance_calc(raw_abundance_file, all_data[\"sample_data\"])\n",
    "        except Exception as e:\n",
    "            print(\"Abundance process went wrong.\",e)\n",
    "            normalised_abundance_dataframe = None\n",
    "    else:\n",
    "        normalised_abundance_dataframe = None\n",
    "\n",
    "    if taxonomic_path is not None:\n",
    "        try:\n",
    "            raw_taxonomic_data = open_tsv(taxonomic_path)\n",
    "            long_taxonomic_data = taxonomic_data_long_format(\n",
    "                    raw_taxonomic_data, get_bin_list(all_data[\"sample_data\"]), all_data[\"metadata\"].columns[1:],all_data[\"metadata\"]\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(\"Taxonomy process went wrong.\", e)\n",
    "            long_taxonomic_data = None\n",
    "    else:\n",
    "        long_taxonomic_data = None\n",
    "\n",
    "    total_production_dataframe = total_production_by_sample(all_data[\"main_dataframe\"], all_data[\"sample_data\"], all_data[\"metadata\"], normalised_abundance_dataframe)\n",
    "\n",
    "    return all_data, normalised_abundance_dataframe, long_taxonomic_data, total_production_dataframe\n",
    "\n",
    "\n",
    "def producers_by_compound_and_samples(all_data: dict, metadata: pd.DataFrame):\n",
    "    all_producers = []\n",
    "    for sample in all_data.keys():\n",
    "        serie_value = []\n",
    "        serie_index = []\n",
    "        df = all_data[sample][\"cscope\"]\n",
    "        for i in range(len(df.columns)):\n",
    "            serie_index.append(df.columns[i])\n",
    "            serie_value.append(df[df.columns[i]].to_numpy().sum())\n",
    "        all_producers.append(pd.Series(serie_value,index=serie_index,name=sample))\n",
    "\n",
    "    res = pd.concat(all_producers,axis=1).T\n",
    "    res.fillna(0,inplace=True)\n",
    "    res.index.name = \"smplID\"\n",
    "    res.reset_index(inplace=True)\n",
    "    res = pd.merge(res,metadata,'outer',\"smplID\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def producers_by_compounds_and_samples_multi(all_data: dict, metadata: pd.DataFrame):\n",
    "        \n",
    "    cpu_available = cpu_count() - 1\n",
    "    if not type(cpu_available) == int or cpu_available < 1:\n",
    "        cpu_available = 1\n",
    "    pool = Pool(cpu_available)\n",
    "    all_producers = pool.starmap(individual_producers_processing,[(all_data[sample][\"cscope\"], sample) for sample in all_data.keys()])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    res = pd.concat(all_producers,axis=1).T\n",
    "    res.fillna(0,inplace=True)\n",
    "    res.index.name = \"smplID\"\n",
    "    res.reset_index(inplace=True)\n",
    "    res = pd.merge(res,metadata,'outer',\"smplID\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def individual_producers_processing(sample_cscope: pd.DataFrame , sample: str):\n",
    "        serie_value = []\n",
    "        serie_index = []\n",
    "\n",
    "        for i in range(len(sample_cscope.columns)):\n",
    "            serie_index.append(sample_cscope.columns[i])\n",
    "            serie_value.append(sample_cscope[sample_cscope.columns[i]].to_numpy().sum())\n",
    "        return pd.Series(serie_value,index=serie_index,name=sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dir_path = \"/home/lbrindel/output/western_diet_samples/all_samples/\"\n",
    "metadata = \"~/Downloads/western_diet_exp/metadata_drama.tsv\"\n",
    "abundance_path = \"~/Downloads/western_diet_exp/specI.mat\"\n",
    "taxonomic_path = \"~/Downloads/western_diet_exp/taxonomies.tsv\"\n",
    "save_path = \"/home/lbrindel/output/save_output_m2m\"\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "all_data[\"metadata\"] = open_tsv(metadata)\n",
    "\n",
    "all_data[\"sample_data_multi\"] = multiprocess_retrieve_data(dir_path) # 1m 38.6s\n",
    "all_data[\"producers_long_format\"] = producers_by_compound_and_samples(all_data[\"sample_data_multi\"],all_data[\"metadata\"]) # 2m 36.9s (res_smpl1)\n",
    "# CRASH at 17m (all_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/home/lbrindel/output/western_diet_samples/all_samples/\"\n",
    "metadata = \"~/Downloads/western_diet_exp/metadata_drama.tsv\"\n",
    "abundance_path = \"~/Downloads/western_diet_exp/specI.mat\"\n",
    "taxonomic_path = \"~/Downloads/western_diet_exp/taxonomies.tsv\"\n",
    "save_path = \"/home/lbrindel/output/save_output_m2m\"\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "all_data[\"metadata\"] = open_tsv(metadata)\n",
    "\n",
    "all_data[\"sample_data\"] = multiprocess_retrieve_data(dir_path) # 4m 15.3s old ways\n",
    "all_data[\"producers_long_format\"] = producers_by_compounds_and_samples_multi(all_data[\"sample_data\"],all_data[\"metadata\"]) # 1m 46s (res_smpl1)\n",
    "# 8m 6.6s (all_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmbo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
